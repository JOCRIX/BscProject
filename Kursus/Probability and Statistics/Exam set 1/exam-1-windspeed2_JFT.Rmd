---
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r , include=FALSE}
library(mosaic) # load the mosaic package for later use
library(jpeg)
library(gridExtra)
library(png)
```

# Exam exercise for Module 1: Wind speed distributions

```{r, fig.width=10, echo=FALSE, fig.align='center'}
# was ![](https://asta.math.aau.dk/static-files/asta/img/mills.jpg)
url <- "https://asta.math.aau.dk/static-files/asta/img/mills.jpg"
z <- tempfile()
download.file(url, z, mode = "wb")
grid::grid.raster(jpeg::readJPEG(z))
invisible(file.remove(z))
```




In this workshop we consider a continuous probability distribution
called the Weibull distribution. Among other things, it is used to model
wind speed distributions.

We recommend that you answer the
exercises using Rmarkdown (you can simply use the exam Rmarkdown file as
a starting point).


# Part I: The Weibull distribution

The Weibull distribution depends on two parameters $k>0$ and $\lambda>0$. If
$X$ follows a Weibull distribution with parameters $k$ and $\lambda$, we
write $X\sim \texttt{weibull}(k,\lambda)$. In this case, $X$ has the
probability density function
$$f(x)=\begin{cases}\frac{k}{\lambda}\left( \frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^k},& x \geq 0,\\
0,&x< 0,\end{cases}$$
and the distribution function
$$
F(x)=\begin{cases}1 - e^{-(x/\lambda)^k},& x \geq 0,\\
0,&x < 0.\end{cases}$$

The parameter $k$ is called the shape parameter, since it determines the
shape of the distribution, while $\lambda$ is called the scale
parameter, because it works by scaling the $x$-axis. 

1.   Use the `mosaic` package with the `plotDist` function to make plots of 
     different parameter combinations to demonstrate that $\lambda$ is a scale parameter 
     and $k$ is a shape parameter. (Hint: `plotDist("weibull", params = list(shape = ., scale = .))`)
     First we run the variable k or shape through 1 to 10 and see how the shape changes, it changes from skewed to the left to be skewed to the right.
```{r}
lambda <- 1
k <- 1
w1 <- plotDist("weibull", params = list(shape = k, scale = lambda))
k <- 2
w2 <- plotDist("weibull", params = list(shape = k, scale = lambda))
k <-5
w3 <- plotDist("weibull", params = list(shape = k, scale = lambda))
k <- 10
w4 <- plotDist("weibull", params = list(shape = k, scale = lambda))
grid.arrange(w1, w2, w3, w4, ncol = 2)
```
We then the run the same changes but for lambda and see how the scale changes:
```{r}
lambda <- 1
k <- 4
w1 <- plotDist("weibull", params = list(shape = k, scale = lambda))
lambda <- 2
w2 <- plotDist("weibull", params = list(shape = k, scale = lambda))
lambda <-5
w3 <- plotDist("weibull", params = list(shape = k, scale = lambda))
lambda <- 10
w4 <- plotDist("weibull", params = list(shape = k, scale = lambda))
grid.arrange(w1, w2, w3, w4, ncol = 2)
```
Here we see that lambda defines how "sharp" or "pointy" the function is, larger lambda means longer tails or larger variance. It also seems that the center is around lambdas value.


2.  Assume that $x \geq 0$. Show that the distribution function $F(x)$ satisfies
    $$\ln(-\ln(1-F(x)))=-k\ln(\lambda) + k\ln(x).$$
```{r}

library("png")
pp <- readPNG("1.2.png")
plot.new() 
rasterImage(pp,0,0,1,1)


```
    

# Part II: Wind speed measurements


In this part we consider a data set containing wind speed measurements
from a Danish weather station located at SjÃ¦lsmark. The data set
contains the wind speed measured at 12 noon every day of January in the
years 2001-2019. We first load the data set:

```{r}
speed<-read.delim("https://asta.math.aau.dk/datasets?file=windSpeed.txt",header=FALSE)[,1]
```

1.  Draw a histogram of the wind speed observations by editing the R
    chunk below. Explain how a histogram is constructed. Do you think
    the observations come from a normal distribution?

```{r}
#hist(speed) 
gf_histogram(~speed,bins=15)
```
A histogram shows how many times something ocoured in a given interval. in this instance, we want 15 bins, such that the largest bin describe the maximum outcome. In this instance the max is 15, and thus we get that the bin size should be 15/15 = 1.
Thus the first bin describes all counts in the interval 0 - 0.999 m/s. bin 2 describes from 1.. to 1.999 m/s etc. The y axis is the count, i.e. it is the total number of ocourances that fall in a given interval. A histrogram can be used to show the distribution of a measured system.

This is clearly bot gaussian (normal), it is skewed, and looks a lot like Weibull dist. with k approx. around 2, see figures from task 1.


In the following we will convince ourselves that the data actually comes
from a Weibull distribution. We order the $n=589$ observations from
smallest to largest $$x_{(1)}\leq x_{(2)}\leq \dotsm \leq x_{(n)}.$$

2.  Argue that $F(x_{(i)})\approx \tfrac{i}{n}$ for $i=1,\ldots,n$. (Hint: How many observations are less than or equal to $x_{(i)}$?)

The distribution funciton F(x), gives the probability of a value being in the range from 0 to x. Thus if we where to compute F(10) it would return the probability of getting a value from 0 to 10. Much in the same way,
if we say i =250, and compute 250/589 = 0.424 this means, that the probability of an output being in the span from 0 to the x value at index 250 would be 0.424. In other words, we know that all value below the i'th index must be smaller than the value at the i'th index and as such i/n approximates F(x).

First and formost the distribution fuction must have an area of 1 at infinity. The infitnity in our discrete case 


3.  Using Exercise 2 in Part I, argue that if the observations come from
    a $\texttt{weibull}(k,\lambda)$ distribution, then
    $$\ln(-\ln(1-\tfrac{i}{n}))\approx -k\ln(\lambda) + k\ln(x_{(i)}).$$

We earlier showed that the equation is true, And we have now reasoned that i/n approximates F(x), thus if x(i) approximates x in a discrete case, then we conclude that the discrete equation must be approximately true as well.

The code below computes a vector containing the values
$v_i=\ln(-\ln(1-\tfrac{i}{n}))$ and a vector containing the values
$u_i = \ln(x_{(i)}).$

By plotting both v and u, we see that they both follow the same curve, thus if we plot a scatterplot of Q-Q plot we would expect a linear relationship.
One way to look at this is, that we i/n is a linear plot, and -ln(1-i/n) very closely approximates an exponential function, as seen in the plots. At the same time,
the sorted function xi also follows a somewhat exponential growth, given it is sorted. We can do a scatterplot for the sorted xi and -log(1-i/n) and see
that it is somewhat linear, and once again, when we take log of both sides, we would again expect a linear hehaviour.

Another reasonanle explanation would be that i/n approximates F(x), and F(x) is an exponential function, thus -ln(1-F(x)) would be expected to behave linearly.
we then take ln again such that we have ln(-ln(1-F(x))) and thus should behave like a log function. On the other side we have a linear function x, and we take
ln(x), resulting in a log behaviour, and plotting a log log function will yield a linear graph.

```{r, message=FALSE}
n<-length(speed)
sortedSpeed<-sort(speed)
u<-log(sortedSpeed)
CDF<-(1:n)/n
v<-log(-log(1-CDF))
#gf_point(v ~ u)
plt1 <- plot(sortedSpeed)
plt2 <- plot(-log(1-CDF))
plt3 <- gf_point(-log(1-CDF) ~ sortedSpeed)
plt4 <- gf_point(v~u)%>%gf_lm()
grid.arrange(plt1, plt2, plt3, plt4, ncol = 2)
#gf_point(...~...) %>%gf_lm()

```

4.  Argue that the points $(u_i,v_i)$ should lie approximately on a
    straight line if the observations come from a
    $\texttt{weibull}(k,\lambda)$ distribution. Edit the code above to
    check that this is the case.

5.  The intercept and slope of the line can be found to be $-2.82$ and
    $1.78$, respectively. Use this to give estimates of the parameters
    $k$ and $\lambda$ of the model. Insert these values in the code
    below to plot the histogram together with the approximate density
    (`shape` is $k$ and `scale` is $\lambda$).

```{r}
plt5 <- plotDist("weibull", params = list(shape = 1.78, scale = 4.876))
plt6 <- gf_dhistogram( ~ speed, bins = 20)
grid.arrange(plt5, plt6, ncol = 2)
 #%>%
#gf_dist("weibull", shape = ..., scale = ..., col = "red")
```

We can see the QQ plot as a xy plot, where x is -k ln(lambda)+k ln(xi) and y is ln(-ln(1-i/n)).
We know that it forms a straight line, and as such, we can see the right side as the "input" and the left side as the "output".
A linaer fit follows the form a*x+b where b is the value of intersection with the y axis, and a is the slope if the line. 

On the left side of the equation we have -k ln(lambda) + k ln(x),
we know -k ln(lambda) the be a constant so this must be b, and we can see k at the slope of the line. Thus wee can find the intersection value simply by knowing that k is the slope. We simply only look at -k (lambda). 
we can make the expression, y_c = -k (lambda) -> -y_c/k = ln(lambda)
-> e^(-y_c/k) = lambda, and with the given values we get:
lambda = e^(-(-2.82)/1.78) = 4.876 we then have:
lambda = 4.876
k = 1.78

We reason that the slope is k, by seing it as a log plot, so the input is ln(x) and the multiplier of this is simply k, so the slope must be k.

# Part III: Sample mean and the central limit theorem

In this last exercise, we investigate the distribution of the sample
mean when a random sample is taken from a population having a
$\texttt{weibull}(k,\lambda)$ distribution. We will use the values of
$k$ and $\lambda$ that you found in Part II, Exercise 5 to mimic a
sample of wind speed measurements.

Denote by $\mu$ the mean of the 
population distribution, $\texttt{weibull}(k, \lambda)$, 
and by $\sigma^2$ the variance of the population distribution. 

The numeric values of $\mu$ and $\sigma^2$ for choices of $\lambda$ and $k$ 
can be calculated 
$\mu = \lambda \Gamma(1 + 1/k)$ and 
$\sigma^2 = \lambda^2 \left [ \Gamma\left( 1 + 2/k \right ) - \left \{ \Gamma\left( 1 + 1/k \right ) \right \}^2 \right ]$, 
where $\Gamma(x)$ denotes the gamma function. 

1.  Using the values of $k$ and $\lambda$ from Part II, Exercise 5, 
    what is the mean and standard deviation? 
    (Hint: You can use the function `gamma()` in R to compute the gamma function.)
    
```{r}
la <- 4.876
k <- 1.78
mu <- la*gamma(1+(1/k))
variance <- (la^2)*(gamma(1+2/k)-(gamma(1+1/k))^2)
STD <- sqrt(variance)
print(mu)
print(STD)
```


2.  Suppose that a sample consists of 30 observations from this
    distribution. We denote the sample mean by `x_bar`. Using the
    central limit theorem, answer the following questions:

-   What is the expected value of `x_bar`?
-   What is the standard deviation of `x_bar` (also called the standard
    error)?
-   What is the approximate distribution of `x_bar`?

The code below generates 30 independent realizations of a Weibull
distribution with parameters $k$ and $\lambda$. One may think of this of
as simulated random sample of 30 independent wind speed observations.

The expected value is quite simply the mean. Note that the following function simply gives a ramndom weibull set with 30 samples.
To find the standard deviation of the expected value (a mean) we find the standard deviation of the set, and device by sqrt(n)
```{r}
x<-rweibull(30, shape=k, scale = la )
n <- 30
xbar <- mean(x)
SEM_xbar = sd(x)/sqrt(n)
print(xbar)
print(SEM_xbar)
```
x_bar will approximately be of normal distribution, but given the limited set of sampels, it would be closer to t distributed with larger tails than that of normal distribution.

3.  Insert the values of $k$ and $\lambda$ from Part II, Exercise 5 in
    the code. Run the command a few times. Is each sample mean close to
    what you expected?

Use `replicate` to repeat the sampling 500 times and save each mean
value in the vector `x_bar`:

```{r}
x_bar1 <- replicate(500, mean(rweibull(30, shape=k, scale = la) ))
x_bar2 <- replicate(500, mean(rweibull(30, shape=k, scale = la) ))
x_bar3 <- replicate(500, mean(rweibull(30, shape=k, scale = la) ))
x_bar4 <- replicate(500, mean(rweibull(30, shape=k, scale = la) ))
hist1 <- gf_dhistogram( ~ x_bar, bins = 25)
hist2 <- gf_dhistogram( ~ x_bar, bins = 25)
hist3 <- gf_dhistogram( ~ x_bar, bins = 25)
hist4 <- gf_dhistogram( ~ x_bar, bins = 25)
grid.arrange(hist1, hist2, hist3, hist4, ncol = 2)
```
Here we have 4 instances, and we see that the mean will tend to be around the expected 4.3, and that each instance approximates normal dist. 

We get that the true mean is 4.33 from earlier.


4.  Calculate the mean and standard deviation of the values in `x_bar`.
    How do they match with what you expected?

Here we use x_bar1
```{r}
mean(x_bar1)
mean(x_bar2)
mean(x_bar3)
mean(x_bar4)
sd(x_bar1)
sd(x_bar2)
sd(x_bar3)
sd(x_bar4)
```
They match a value that is amazingly close to the population mean, with a very small SEM.

5.  Make a QQ-plot to assess the distribution of `x_bar`. Does this look
    like what you would expect?
    
```{r}
qqnorm(x_bar1)
qqline(x_bar1)
```

The slope is approximately 0.45, approximating the standard deviation, and the intercept is about 4.3 apprioximating the mean.